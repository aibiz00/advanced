{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119bbd17",
   "metadata": {},
   "source": [
    "# [2차시] 실습을 통한 딥러닝 Auto encoder 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b67663",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9324a18a",
   "metadata": {},
   "source": [
    "* 오늘은 입력값만으로 학습하는 오토인코더를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5e010",
   "metadata": {},
   "source": [
    "* 지도학습은 단순히 말해 입력 x와 정답 y 사이의 관계를 찾는 것이고, 비지도 학습은 정답이 없는 채로 x를 예측합니다.\n",
    "* x를 예측하고, 신경망에 의미 있는 정보가 쌓이도록 설계된 신경망이 바로 오토인코더입니다. 즉 오토인코더에서는 입력도 x, 정답도 x 입니다.\n",
    "* 단, 신경망은 범용근사자(univeral function approximator)로서 근사치를 출력하므로 x와 똑같은 출력을 내긴 힘듭니다.\n",
    "* 그러므로 오찻값에도 x를 얼마나 복원했는지를 뜻하는 복원오차, 혹은 정보손실값(reconstruction loss)이라는 용어를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0021b",
   "metadata": {},
   "source": [
    "* 오토인코더는 입력과 출력의 크기는 같지만 중간으로 갈수록 신경망의 차원이 줄어든다는 것입니다.\n",
    "* 작은 차원으로 압축된 표현을 잠재변수(latent variable)라 하고, 간단히 z라고도 합니다.\n",
    "* 잠재 변수의 앞뒤를 구분하여 앞부분을 인코더(encoder), 뒷부분을 디코더(decoder)라고 합니다.인코더는 정보를 받아 압축하고, 디코더는 압축된 표현을 풀어 입력을 복원하는 역할을 합니다.\n",
    "* 오토인코더에서는 필연적으로 정보의 손실이 일어나지만 이는 중요한 정보만 남겨두는 일종의 데이터 가공이라고 볼 수 있습니다. 이런 특징으로 인해 오토인코더는 주로 복잡한 비선형 데이터의 차원을 줄이는 용도로 쓰입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "344c4edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\python\\lesson\\lib\\site-packages (2.10.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (3.19.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (2.12.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (1.49.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (3.4.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (68.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (1.23.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python\\lesson\\lib\\site-packages (from tensorboard) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python\\lesson\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python\\lesson\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python\\lesson\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python\\lesson\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python\\lesson\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\python\\lesson\\lib\\site-packages (from markdown>=2.6.8->tensorboard) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python\\lesson\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lesson\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\python\\lesson\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lesson\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\python\\lesson\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\python\\lesson\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python\\lesson\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python\\lesson\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#tensorboard 설치\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a709a2",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d670c5e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:25:50.067379Z",
     "start_time": "2022-02-16T04:25:50.053418Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\tensorboard\\compat\\__init__.py:42\u001b[0m, in \u001b[0;36mtf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (C:\\python\\lesson\\lib\\site-packages\\tensorboard\\compat\\__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, optim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, datasets\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmpl_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmplot3d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Axes3D \n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m LooseVersion\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tensorboard\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecord_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordWriter\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_file_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventFileWriter\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_convert_np\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_np\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_embedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     make_mat,\n\u001b[0;32m     18\u001b[0m     make_sprite,\n\u001b[0;32m     19\u001b[0m     make_tsv,\n\u001b[0;32m     20\u001b[0m     write_pbtxt,\n\u001b[0;32m     21\u001b[0m     get_embedding_info,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onnx_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_onnx_graph\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pytorch_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\torch\\utils\\tensorboard\\_embedding.py:9\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector_config_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingInfo\n\u001b[1;32m----> 9\u001b[0m _HAS_GFILE_JOIN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mgfile, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gfile_join\u001b[39m(a, b):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# The join API is different between tensorboard's TF stub and TF:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# https://github.com/tensorflow/tensorboard/issues/6080\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# We need to try both because `tf` may point to either the stub or the real TF.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _HAS_GFILE_JOIN:\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\tensorboard\\lazy.py:65\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.LazyModule.__getattr__\u001b[1;34m(self, attr_name)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mload_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m, attr_name)\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\tensorboard\\lazy.py:97\u001b[0m, in \u001b[0;36m_memoize.<locals>.wrapper\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cache\u001b[38;5;241m.\u001b[39mget(arg, nothing) \u001b[38;5;129;01mis\u001b[39;00m nothing:\n\u001b[1;32m---> 97\u001b[0m             cache[arg] \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[arg]\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\tensorboard\\lazy.py:50\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.load_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m load_once\u001b[38;5;241m.\u001b[39mloading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     load_once\u001b[38;5;241m.\u001b[39mloading \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\tensorboard\\compat\\__init__.py:45\u001b[0m, in \u001b[0;36mtf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensorflow\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\tensorflow\\__init__.py:469\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_current_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    468\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 469\u001b[0m     \u001b[43m_keras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\pitbull\\appdata\\local\\programs\\python\\python38\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\engine\\functional.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_utils\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\engine\\training.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_utils\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_layer \u001b[38;5;28;01mas\u001b[39;00m input_layer_module\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\engine\\compile_utils.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses \u001b[38;5;28;01mas\u001b[39;00m losses_mod\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics \u001b[38;5;28;01mas\u001b[39;00m metrics_mod\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\metrics\\__init__.py:33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_metric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone_metrics\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Metric functions\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Individual metric classes\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUC\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accuracy\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryAccuracy\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\metrics\\metrics.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m dtensor_utils\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\activations.py:21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivation\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mactivation_layers\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\layers\\__init__.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_preprocessing_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreprocessingLayer\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Generic layers.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py:21\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_adapter\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_utils\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\keras\\engine\\data_adapter.py:43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     pd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\pandas\\__init__.py:138\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    121\u001b[0m     concat,\n\u001b[0;32m    122\u001b[0m     lreshape,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m     qcut,\n\u001b[0;32m    135\u001b[0m )\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing  \u001b[38;5;66;03m# noqa:PDF015\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     ExcelFile,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m     read_spss,\n\u001b[0;32m    172\u001b[0m )\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\pandas\\testing.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mPublic testing utility functions.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     assert_extension_array_equal,\n\u001b[0;32m      8\u001b[0m     assert_frame_equal,\n\u001b[0;32m      9\u001b[0m     assert_index_equal,\n\u001b[0;32m     10\u001b[0m     assert_series_equal,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_extension_array_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_frame_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_series_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_index_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m ]\n",
      "File \u001b[1;32mC:\\python\\lesson\\lib\\site-packages\\pandas\\_testing\\__init__.py:903\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest\u001b[38;5;241m.\u001b[39mraises(expected_exception, match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# noqa: PDF010\u001b[39;00m\n\u001b[1;32m--> 903\u001b[0m cython_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39m_cython_table\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;124;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    keys and expected result.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;124;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "# torch, torchvision 등의 필요한 패키지 import\n",
    "# from mpl_toolkits.mplot3d import Axes3D #생성되는 이미지를 관찰하기 위함입니다. 3차원 플롯을 그리는 용도입니다.\n",
    "# from matplotlib import cm # 데이터포인트에 색상을 입히는 것에 사용됩니다.\n",
    "# 재현성을 보장하기 위해 random_seed로 고정하도록 하겠습니다.\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "from matplotlib import cm \n",
    "import numpy as np\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa82cb",
   "metadata": {},
   "source": [
    "### 오토인코더로 이미지 특징 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfbf399f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:26:03.006761Z",
     "start_time": "2022-02-16T04:26:02.987846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 준비\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = 'cpu'\n",
    "print(\"Using Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef129314",
   "metadata": {},
   "source": [
    "### Fashion MNIST 데이터셋 생성 (학습데이터만 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5260f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:26:22.449478Z",
     "start_time": "2022-02-16T04:26:22.211119Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# root='data/', transforms.ToTensor()를 사용하여 FashionMNIST 데이터셋을 생성하십시오.\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = 'data/', \n",
    "    train     = True,\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354171f9",
   "metadata": {},
   "source": [
    "### Fashion MNIST train 데이터셋 DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2adbf348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성한 train dataset을 shuffle, num_workers=2, batch_size 를 사용하여 torch.utils.data.DataLoader()로 생성하십시오\n",
    "# Create Discriminator Network\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,\n",
    "    num_workers = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c4346",
   "metadata": {
    "id": "Eb1rVzijlOSn"
   },
   "source": [
    "# Create Autoencoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77633033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오토인코더 모듈 정의\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        #인코더는 간단한 신경망으로 분류모델처럼 생겼습니다.\n",
    "        self.encoder = nn.Sequential( # nn.Sequential을 사용해 encoder와 decoder 두 모듈로 묶어줍니다.\n",
    "            nn.Linear(28*28, 128), #차원을 28*28에서 점차 줄여나갑니다.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 3),   # 입력의 특징을 3차원으로 압축합니다 (출력값이 바로 잠재변수가 됩니다.)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12), #디코더는 차원을 점차 28*28로 복원합니다.\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid(),       # 픽셀당 0과 1 사이로 값을 출력하는 sigmoid()함수를 추가합니다.\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x) # encoder는 encoded라는 잠재변수를 만들고\n",
    "        decoded = self.decoder(encoded) # decoder를 통해 decoded라는 복원이미지를 만듭니다.\n",
    "        return encoded, decoded# Create Discriminator Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b300369",
   "metadata": {},
   "source": [
    "# 손실함수, optimizer, 스케줄러를 생성하십시오.\n",
    "- Adam()을 최적화함수로 사용합니다. Adam은 SGD의 변형함수이며 학습중인 기울기를 참고하여 학습 속도를 자동으로 변화시킵니다.\n",
    "- 원본값과 디코더에서 나온 값의 차이를 계산하기 위해 평균제곱오차(Mean Squared Loss) 오차함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "073f4833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:31:20.285114Z",
     "start_time": "2022-02-16T04:31:20.251175Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SummaryWriter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(autoencoder\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m) \n\u001b[0;32m      7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss() \n\u001b[1;32m----> 8\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./runs/simple_experiment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SummaryWriter' is not defined"
     ]
    }
   ],
   "source": [
    "# 생성한 Autoencoder 모듈을 'cpu'를 사용하여 instance 하십시오.\n",
    "# nn.MSELoss()를 사용하여 손실함수를 생성하십시오.\n",
    "# torch.optim.Adam()을 사용하여 lr=0.005인 옵티마이저를 생성하십시오.\n",
    "\n",
    "autoencoder = Autoencoder().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.005) \n",
    "criterion = nn.MSELoss() \n",
    "writer = SummaryWriter('./runs/simple_experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a4b3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pitbull\\\\Desktop\\\\고급\\\\실습파일\\\\2차시'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b8f57",
   "metadata": {},
   "source": [
    "# 시각화를 위한 변수 생성\n",
    "- 픽셀의 색상값이 0~255이므로 모델이 인식하는 0부터 1사이의 값으로 만들기 위해 255로 나눠줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876c2d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:32:48.985845Z",
     "start_time": "2022-02-16T04:32:48.948938Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습 데이터셋에서 5개의 이미지만 가져와서 view(-1, 28*28) 사용하여 생성하십시오.\n",
    "# 생성한 데이터 픽셀을 type(torch.FloatTensor)/255. 사용하여 정규화 해주십시오. \n",
    "\n",
    "view_data = trainset.data[:5].view(-1, 28*28)\n",
    "view_data = view_data.type(torch.FloatTensor)/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c929d83",
   "metadata": {},
   "source": [
    "# 학습 함수 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8354124",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:34:37.171681Z",
     "start_time": "2022-02-16T04:34:37.160711Z"
    }
   },
   "outputs": [],
   "source": [
    "# 학습하기 위한 함수\n",
    "def train(epoch, autoencoder, train_loader):\n",
    "    autoencoder.train()\n",
    "    for step, (x, label) in enumerate(train_loader):\n",
    "        x = x.view(-1, 28*28).to(DEVICE)\n",
    "        y = x.view(-1, 28*28).to(DEVICE) #x(입력)와 y(대상 레이블)모두 원본이미지(x)인 것을 주의해야 합니다.\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        encoded, decoded = autoencoder(x)\n",
    "\n",
    "        loss = criterion(decoded, y) # decoded와 원본이미지(y) 사이의 평균제곱오차를 구합니다\n",
    "        optimizer.zero_grad() #기울기에 대한 정보를 초기화합니다.\n",
    "        loss.backward() # 기울기를 구합니다.\n",
    "        optimizer.step() #최적화를 진행합니다.\n",
    "        writer.add_scalar('Train/Loss', loss.item(), epoch * len(train_loader) + step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e135f18",
   "metadata": {},
   "source": [
    "# 학습 시작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84622dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:41:58.407385Z",
     "start_time": "2022-02-16T04:38:05.380337Z"
    }
   },
   "outputs": [],
   "source": [
    "# epoch마다 학습하기 위해 생성한 함수에 autoencoder와 train_loader를 넣어서 학습하십시오.\n",
    "# 앞서 시각화를 위해 남겨둔 5개의 이미지를 한 epoch만큼 학습을 마친 모델에 넣어 복원이미지를 생성하십시오.\n",
    "# 원본과 디코딩 결과 비교를 위한 시각화를 진행하십시오.\n",
    "\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    train(epoch, autoencoder, train_loader)\n",
    "\n",
    "    test_x = view_data.to(DEVICE)\n",
    "    _, decoded_data = autoencoder(test_x)\n",
    "\n",
    "    # 원본과 디코딩 결과 비교해보기\n",
    "    f, a = plt.subplots(2, 5, figsize=(5, 2))\n",
    "    print(\"[Epoch {}]\".format(epoch))\n",
    "    for i in range(5):\n",
    "        img = np.reshape(view_data.data.numpy()[i],(28, 28)) #파이토치 텐서를 넘파이로 변환합니다.\n",
    "        a[0][i].imshow(img, cmap='gray')\n",
    "        a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "    for i in range(5):\n",
    "        img = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28, 28)) \n",
    "        a[1][i].imshow(img, cmap='gray')\n",
    "        a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4274be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard를 활용한 학습 과정보기\n",
    "\n",
    "!tensorboard --logdir=runs\n",
    "# 웹브라우저에 http://localhost:6006/ 접속"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6413e098",
   "metadata": {},
   "source": [
    "### 잠재변수 들여다보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a112381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:43:18.434791Z",
     "start_time": "2022-02-16T04:43:18.417839Z"
    }
   },
   "outputs": [],
   "source": [
    "# 잠재변수를 3D 플롯으로 시각화\n",
    "# 학습 데이터셋에서 200개의 이미지만 가져와서 view(-1, 28*28) 사용하여 생성하십시오.\n",
    "# 생성한 데이터 픽셀을 type(torch.FloatTensor)/255. 사용하여 정규화 해주십시오. \n",
    "# 정규화한 데이터를 'cpu' 모드로 변경하고 autoencoder를 적용하십시오.\n",
    "# 추출한 데이터를 다시 'cpu' 모드로 변경하십시오.\n",
    "\n",
    "view_data = trainset.data[:200].view(-1, 28*28) #원본이미지 200개를 준비합니다\n",
    "view_data = view_data.type(torch.FloatTensor)/255.\n",
    "test_x = view_data.to(DEVICE)\n",
    "encoded_data, _ = autoencoder(test_x)\n",
    "encoded_data = encoded_data.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d91f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:44:49.125686Z",
     "start_time": "2022-02-16T04:44:47.274633Z"
    }
   },
   "outputs": [],
   "source": [
    "# FMNIST 데이터셋의 클래스를 딕셔너리로 정의하십시오.\n",
    "# 0: 'T-shirt/top', 1: 'Trouser', 2: 'Pullover', 3: 'Dress', 4: 'Coat', 5: 'Sandal', 6: 'Shirt', 7: 'Sneaker', 8: 'Bag', 9: 'Ankle boot'\n",
    "# Axes3D plot을 생성하십시오,\n",
    "# 인코딩된 데이터를 각각 data[:, 0].numpy(), data[:, 1].numpy(), data[:, 2].numpy()를 사용하여 \n",
    "# 잠재변수의 각 차원을 numpy행렬로 변환하십시오.\n",
    "# 가져온 200개 이미지의 레이블도 numpy행렬로 변환하십시오.\n",
    "# 잠재변수와 라벨링을 zip()함수를 사용하여 class명과 rainbow(int(255*class명/9))을 사용하여 text를 추가하십시오.\n",
    "\n",
    "CLASSES = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "X = encoded_data.data[:, 0].numpy()\n",
    "Y = encoded_data.data[:, 1].numpy()\n",
    "Z = encoded_data.data[:, 2].numpy() #잠재변수의 각 차원을 numpy행렬로 변환합니다.\n",
    "\n",
    "labels = trainset.targets[:200].numpy() #레이블도 넘파이행렬로 변환합니다.\n",
    "\n",
    "for x, y, z, s in zip(X, Y, Z, labels): #zip()은 같은 길이의 행렬들을 모아 순서대로 묶어줍니다.\n",
    "    name = CLASSES[s]\n",
    "    color = cm.rainbow(int(255*s/9))\n",
    "    ax.text(x, y, z, name, backgroundcolor=color)\n",
    "\n",
    "ax.set_xlim(X.min(), X.max())\n",
    "ax.set_ylim(Y.min(), Y.max())\n",
    "ax.set_zlim(Z.min(), Z.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d32b95",
   "metadata": {},
   "source": [
    "* 같은 레이블을 가진 이미지의 잠재변수는 확연히 서로 모임을 알 수 있습니다.\n",
    "* 티셔츠, 드레스, 코트, 셔츠와 같은 윗옷들끼리의 거리는 가깝거나 겹치고, 신발류인 앵클부츠, 샌들, 운동화도 서로 가까이 자리하는 것을 볼 수 있습니다.\n",
    "* 즉, 비슷한 의미의 이미지라면 공간적으로 더 까갑습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aa7ce1",
   "metadata": {},
   "source": [
    "### 연습문제\n",
    "### 오토인코더로 망가진 이미지 복원하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286bc71f",
   "metadata": {},
   "source": [
    "* 잡음제거 오토인코더(Denoising Autoencoder)는 2008년 몬트리올 대학에서 발표한 논문 \"Extracting and Composing Robust Features with Denoising AutoEncoder\" 에서 처음 제안되었습니다.\n",
    "\n",
    "* 앞서 오토인코더는 일종의 \"압축\"을 한다고 했습니다. 그리고 압축은 데이터의 특성에 중요도로 우선순위를 매기고 낮은 우선순위의 데이터를 버린다는 뜻이기도 합니다.\n",
    "\n",
    "* 잡음제거 오토인코더의 아이디어는 중요한 특징을 추출하는 오토인코더의 특성을 이용하여 비교적 \"덜 중요한 데이터\"인 잡음을 버려 원래의 데이터를 복원한다는 것 입니다. 원래 배웠던 오토인코더와 큰 차이점은 없으며, 학습을 할때 입력에 잡음을 더하는 방식으로 복원 능력을 강화한 것이 핵심입니다.\n",
    "\n",
    "* 앞서 다룬 코드와 동일하며 add_noise() 함수로 학습시 이미지에 노이즈를 더해주는 부분만 추가됐습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1699bced",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:49:19.127850Z",
     "start_time": "2022-02-16T04:49:19.107902Z"
    }
   },
   "outputs": [],
   "source": [
    "# 잡음 추가를 위한 함수를 구성하겠습니다.\n",
    "# 무작위 작음은 torch.randn() 함수로 만들고 img.size()를 넣어 이미지와 같은 크기의 잡음을 만드십시오\n",
    "# 잡음의 강도는 임의로 0.2로 하십시오.\n",
    "# img와 잡음을 더해 출력되게 하십시오.\n",
    "\n",
    "def add_noise(img):\n",
    "    noise = torch.randn(img.size()) * 0.2 \n",
    "    noisy_img = img + noise\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d4e0957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:50:22.206839Z",
     "start_time": "2022-02-16T04:50:22.191881Z"
    }
   },
   "outputs": [],
   "source": [
    "# 기존 학습코드에 생성한 노이즈더하기 코드 한줄을 추가합니다.\n",
    "# 추가적으로 손실값에 item()을 사용하여 평균 오차값을 추가하십시오.\n",
    "\n",
    "\n",
    "def train(autoencoder, train_loader):\n",
    "    autoencoder.train()\n",
    "    avg_loss = 0\n",
    "    for step, (x, label) in enumerate(train_loader):\n",
    "        noisy_x = add_noise(x)  # 입력에 노이즈 더하기\n",
    "        noisy_x = noisy_x.view(-1, 28*28).to(DEVICE)\n",
    "        y = x.view(-1, 28*28).to(DEVICE)\n",
    "\n",
    "        label = label.to(DEVICE)\n",
    "        encoded, decoded = autoencoder(noisy_x)\n",
    "\n",
    "        loss = criterion(decoded, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_loss += loss.item() # 이번에는 평균 오찻값을 관찰하겠습니다.\n",
    "    return avg_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec4fc7e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:54:37.921236Z",
     "start_time": "2022-02-16T04:50:38.816437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] loss:0.035315296993946345\n",
      "[Epoch 2] loss:0.02505670504561111\n",
      "[Epoch 3] loss:0.0239346987927265\n",
      "[Epoch 4] loss:0.023370850716095997\n",
      "[Epoch 5] loss:0.02313259474710742\n",
      "[Epoch 6] loss:0.02286460650747201\n",
      "[Epoch 7] loss:0.022720244601924917\n",
      "[Epoch 8] loss:0.02245868007336725\n",
      "[Epoch 9] loss:0.02237077366147659\n",
      "[Epoch 10] loss:0.02245170987252869\n"
     ]
    }
   ],
   "source": [
    "# loss 계산\n",
    "\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    loss = train(autoencoder, train_loader)\n",
    "    print(\"[Epoch {}] loss:{}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46975ed5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:56:00.989095Z",
     "start_time": "2022-02-16T04:56:00.918285Z"
    }
   },
   "outputs": [],
   "source": [
    "# 잡음제거 시각화\n",
    "# 모델이 학습시 본적이 없는 데이터로 검증하기 위해 테스트 데이터셋을 가져옵니다.\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', \n",
    "    train     = False, #test데이터셋\n",
    "    download  = True,\n",
    "    transform = transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# 테스트셋에서 이미지 한장을 가져옵니다.\n",
    "sample_data = testset.data[0].view(-1, 28*28) #1차원 행렬로 변환합니다\n",
    "sample_data = sample_data.type(torch.FloatTensor)/255.\n",
    "\n",
    "# 이미지를 add_noise로 오염시킨 후, 모델에 통과시킵니다.\n",
    "original_x = sample_data[0]\n",
    "noisy_x = add_noise(original_x).to(DEVICE)\n",
    "_, recovered_x = autoencoder(noisy_x) #인코딩된 것은 무시하고 복원된 이미지만 보기 위해 첫 변수는 \"_\"로 이름 짓습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2d054ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T04:56:37.211600Z",
     "start_time": "2022-02-16T04:56:36.651103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLkAAAGXCAYAAABfpYIsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSLElEQVR4nO3deXhUhdn38d9kmyRkAwJZWBNAdlBBEEEBoSyuKFJXBKVYfaAuqG2xKlXft7T2uVqeKtblbcUFraCAKyqyuRRQUYyiUHYSIECAJBCyz3n/4GEkss0dMgxn8v1cV64LJr85c5/Z7nPunDnjcRzHEQAAAAAAAOBiEaEuAAAAAAAAADhVDLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuYCf+P3vfy+Px1Or686YMUMej0ebN2+u26KOsHnzZnk8Hs2YMSNotwEAOHMMGDBAAwYMCHUZAACExJIlS+TxeLRkyZJQlwIXYMiFsLJ69WrddNNNatasmbxerzIzM3XjjTdq9erVoS4NABDmDv+hIzY2Vtu2bTvq9wMGDFCXLl1CUBkAIBQO94XDP1FRUWrWrJnGjh17zD4B4NQx5ELYmDNnjs4991wtXLhQt9xyi5566imNGzdOixcv1rnnnqu5c+cGtJwHH3xQpaWltaph9OjRKi0tVatWrWp1fQCA+5WXl+uPf/xjnS3vww8/1IcfflhnywMAnF6PPvqoXnrpJT399NMaPny4Xn75ZfXv319lZWWhLg0IO1GhLgCoCxs2bNDo0aOVnZ2tjz/+WE2aNPH/7q677tKFF16o0aNHKycnR9nZ2cdcRklJiRo0aKCoqChFRdXupREZGanIyMhaXRcAEB7OPvtsPffcc5o8ebIyMzNPeXkxMTF1UBUAIFSGDx+unj17SpJ+8YtfKDU1VX/605/01ltv6ec//3mIqwsen8+niooKxcbGhroU1CMcyYWw8Oc//1kHDx7Us88+W2PAJUmpqal65plnVFJSoscff1zSj+fd+v7773XDDTeoYcOG6tevX43fHam0tFR33nmnUlNTlZiYqCuuuELbtm2Tx+PR73//e3/uWOfkat26tS677DJ9+umn6tWrl2JjY5Wdna0XX3yxxm3s3btX9913n7p27aqEhAQlJSVp+PDh+uabb+rwngIABNsDDzyg6urqkx7NVVVVpccee0xt2rSR1+tV69at9cADD6i8vLxG7ljn5HriiSfUuXNnxcfHq2HDhurZs6deeeUVSdLixYvl8XiOeQTzK6+8Io/Ho2XLlp3aSgIAau3CCy+UdOgP9YetWbNG11xzjRo1aqTY2Fj17NlTb7311lHXLSws1D333KPWrVvL6/WqefPmuvnmm1VQUODP7Nq1S+PGjVNaWppiY2PVvXt3vfDCC/7fV1ZWqlGjRrrllluOWn5xcbFiY2N13333+S8rLy/XlClT1LZtW3m9XrVo0UK//vWvj+pXHo9HEydO1MyZM9W5c2d5vV69//77kqRt27bp1ltvVVpamrxerzp37qx//vOfR91+Xl6eRowYoQYNGqhp06a65557jrod4EQ4kgth4e2331br1q39DeOnLrroIrVu3VrvvvtujctHjRqldu3a6Q9/+IMcxznu8seOHatZs2Zp9OjROv/887V06VJdeumlAde3fv16XXPNNRo3bpzGjBmjf/7znxo7dqx69Oihzp07S5I2btyoefPmadSoUcrKytLOnTv1zDPPqH///vr+++/r5GgAAEDwZWVl6eabb9Zzzz2n3/72t8d9//7FL36hF154Qddcc43uvfderVixQlOnTtUPP/xwwo/YP/fcc7rzzjt1zTXX6K677lJZWZlycnK0YsUK3XDDDRowYIBatGihmTNn6qqrrqpx3ZkzZ6pNmzbq06dPna4zACBwh/8g3rBhQ0mHzivct29fNWvWTL/97W/VoEEDzZo1SyNGjNAbb7zhfy8/cOCALrzwQv3www+69dZbde6556qgoEBvvfWW8vLylJqaqtLSUg0YMEDr16/XxIkTlZWVpdmzZ2vs2LEqLCzUXXfdpejoaF111VWaM2eOnnnmmRpHDM+bN0/l5eW67rrrJB06GuuKK67Qp59+qttuu00dO3bUt99+q7/+9a/6z3/+o3nz5tVYt0WLFmnWrFmaOHGiUlNT1bp1a+3cuVPnn3++fwjWpEkTzZ8/X+PGjVNxcbHuvvtuSYcOLBg0aJC2bt2qO++8U5mZmXrppZe0aNGi4D4gCC8O4HKFhYWOJOfKK688Ye6KK65wJDnFxcXOlClTHEnO9ddff1Tu8O8OW7lypSPJufvuu2vkxo4d60hypkyZ4r/s+eefdyQ5mzZt8l/WqlUrR5Lz8ccf+y/btWuX4/V6nXvvvdd/WVlZmVNdXV3jNjZt2uR4vV7n0UcfrXGZJOf5558/4foCAE6vwz3giy++cDZs2OBERUU5d955p//3/fv3dzp37uw4juOsWrXKkeT84he/qLGM++67z5HkLFq0qMb1+vfv7///lVde6V/O8UyePNnxer1OYWGh/7Jdu3Y5UVFRNfoWACB4DveFjz76yNm9e7eTm5vrvP76606TJk0cr9fr5ObmOo7jOIMGDXK6du3qlJWV+a/r8/mcCy64wGnXrp3/socfftiR5MyZM+eo2/L5fI7jOM60adMcSc7LL7/s/11FRYXTp08fJyEhwSkuLnYcx3E++OADR5Lz9ttv11jOJZdc4mRnZ/v//9JLLzkRERHOJ598UiP39NNPO5Kczz77zH+ZJCciIsJZvXp1jey4ceOcjIwMp6CgoMbl1113nZOcnOwcPHiwRu2zZs3yZ0pKSpy2bds6kpzFixcftd7AT/FxRbje/v37JUmJiYknzB3+fXFxsf+y22+//aTLP3yI7X/913/VuPxXv/pVwDV26tSpxlFmTZo0Ufv27bVx40b/ZV6vVxERh16S1dXV2rNnjxISEtS+fXt99dVXAd8WACD0srOzNXr0aD377LPasWPHUb9/7733JEmTJk2qcfm9994rSUcdeXyklJQU5eXl6Ysvvjhu5uabb1Z5eblef/11/2WvvfaaqqqqdNNNN5nWBQBwagYPHqwmTZqoRYsWuuaaa9SgQQO99dZbat68ufbu3atFixbp5z//ufbv36+CggIVFBRoz549Gjp0qNatW+f/JsY33nhD3bt3P+ooXUn+06289957Sk9P1/XXX+//XXR0tO68804dOHBAS5culSRdfPHFSk1N1WuvvebP7du3TwsWLNC1117rv2z27Nnq2LGjOnTo4K+toKBAF198saRDH5E/Uv/+/dWpUyf//x3H0RtvvKHLL79cjuPUWMbQoUNVVFTk39d57733lJGRoWuuucZ//fj4eN122221u+NRLzHkgusdHl4dHnYdz7GGYVlZWSdd/pYtWxQREXFUtm3btgHX2LJly6Mua9iwofbt2+f/v8/n01//+le1a9dOXq9XqampatKkiXJyclRUVBTwbQEAzgwPPvigqqqqjnlursO95ae9JD09XSkpKdqyZctxl/ub3/xGCQkJ6tWrl9q1a6cJEybos88+q5Hp0KGDzjvvPM2cOdN/2cyZM3X++eeb+hcA4NRNnz5dCxYs0Ouvv65LLrlEBQUF8nq9kg6d1sRxHD300ENq0qRJjZ8pU6ZIOnSOLenQOby6dOlywtvasmWL2rVr5//j+WEdO3b0/16SoqKiNHLkSL355pv+c17NmTNHlZWVNYZc69at0+rVq4+q7ayzzqpR22E/3WfavXu3CgsL/edOPvLn8DnBDi9jy5Ytatu27VHnR27fvv0J1xk4EufkguslJycrIyNDOTk5J8zl5OSoWbNmSkpK8l8WFxcX7PIk6bjfuOgccR6wP/zhD3rooYd066236rHHHlOjRo0UERGhu+++Wz6f77TUCQCoO9nZ2brpppv07LPP6re//e0xMz/dkA9Ex44dtXbtWr3zzjt6//339cYbb+ipp57Sww8/rEceecSfu/nmm3XXXXcpLy9P5eXlWr58uZ588slarw8AoHZ69erl/3bFESNGqF+/frrhhhu0du1a/3b+fffdp6FDhx7z+sH648R1112nZ555RvPnz9eIESM0a9YsdejQQd27d/dnfD6funbtqr/85S/HXEaLFi1q/P+n+1eH1++mm27SmDFjjrmMbt26ncpqADUw5EJYuOyyy/Tcc8/p008/9X9L4pE++eQTbd68Wb/85S/Ny27VqpV8Pp82bdqkdu3a+S9fv379KdX8U6+//roGDhyof/zjHzUuLywsVGpqap3eFgDg9HjwwQf18ssv609/+lONyw/3lnXr1vn/ui5JO3fuVGFhoVq1anXC5TZo0EDXXnutrr32WlVUVOjqq6/W//2//1eTJ0/2f1X7ddddp0mTJunVV19VaWmpoqOja/x1HgBw+kVGRmrq1KkaOHCgnnzySd16662SDn2kcPDgwSe8bps2bfTdd9+dMNOqVSvl5OTI5/PVOJprzZo1/t8fdtFFFykjI0Ovvfaa+vXrp0WLFul3v/vdUbf5zTffaNCgQbX6w0yTJk2UmJio6urqk65fq1at9N1338lxnBq3tXbtWvPtov7i44oIC/fff7/i4uL0y1/+Unv27Knxu7179+r2229XfHy87r//fvOyD/9F5amnnqpx+RNPPFH7go8hMjLyqG94nD17tv8z+AAA92nTpo1uuukmPfPMM8rPz/dffskll0iSpk2bViN/+C/lJ/oG35/2uZiYGHXq1EmO46iystJ/eWpqqoYPH66XX35ZM2fO1LBhw/ijCQCcAQYMGKBevXpp2rRpSkpK0oABA/TMM88c8xyOu3fv9v975MiR+uabb475DbyH9yMuueQS5efn1zjXVlVVlZ544gklJCSof//+/ssjIiJ0zTXX6O2339ZLL72kqqqqo/4Y8vOf/1zbtm3Tc889d9RtlpaWqqSk5ITrGhkZqZEjR+qNN9445oDuyPW75JJLtH379hrnkzx48KCeffbZE94GcCSO5EJYaNeunV544QXdeOON6tq1q8aNG6esrCxt3rxZ//jHP1RQUKBXX31Vbdq0MS+7R48eGjlypKZNm6Y9e/bo/PPP19KlS/Wf//xHUu0+anIsl112mR599FHdcsstuuCCC/Ttt99q5syZys7OrpPlAwBC43e/+51eeuklrV27Vp07d5Ykde/eXWPGjNGzzz6rwsJC9e/fX59//rleeOEFjRgxQgMHDjzu8oYMGaL09HT17dtXaWlp+uGHH/Tkk0/q0ksvPepLWG6++Wb/CXwfe+yx4K0kAMDk/vvv16hRozRjxgxNnz5d/fr1U9euXTV+/HhlZ2dr586dWrZsmfLy8vTNN9/4r/P6669r1KhRuvXWW9WjRw/t3btXb731lp5++ml1795dt912m5555hmNHTtWK1euVOvWrfX666/rs88+07Rp047qE9dee62eeOIJTZkyRV27dq1xdLEkjR49WrNmzdLtt9+uxYsXq2/fvqqurtaaNWs0a9YsffDBB/6PYh7PH//4Ry1evFi9e/fW+PHj1alTJ+3du1dfffWVPvroI+3du1eSNH78eD355JO6+eabtXLlSmVkZOill15SfHx8Hd7zCHcMuRA2Ro0apQ4dOmjq1Kn+wVbjxo01cOBAPfDAAyc9SeOJvPjii0pPT9err76quXPnavDgwXrttdfUvn17/8dCTtUDDzygkpISvfLKK3rttdd07rnn6t133z3ueVwAAO7Qtm1b3XTTTXrhhRdqXP7//t//U3Z2tmbMmKG5c+cqPT1dkydP9p9o+Hh++ctfaubMmfrLX/6iAwcOqHnz5rrzzjv14IMPHpW9/PLL1bBhQ/l8Pl1xxRV1ul4AgNq7+uqr1aZNG/33f/+3xo8fry+//FKPPPKIZsyYoT179qhp06Y655xz9PDDD/uvk5CQoE8++URTpkzR3Llz9cILL6hp06YaNGiQmjdvLunQObGWLFmi3/72t3rhhRdUXFys9u3b6/nnn9fYsWOPquOCCy5QixYtlJube8yPtEdERGjevHn661//qhdffFFz585VfHy8srOzddddd/lPQH8iaWlp+vzzz/Xoo49qzpw5euqpp9S4cWN17ty5xsf54+PjtXDhQv3qV7/SE088ofj4eN14440aPny4hg0bVot7GfWRx/np56MABGTVqlU655xz9PLLL+vGG28MdTkAABylqqpKmZmZuvzyy4865yMAAEC44ZxcQABKS0uPumzatGmKiIjQRRddFIKKAAA4uXnz5mn37t26+eabQ10KAABA0PFxRSAAjz/+uFauXKmBAwcqKipK8+fP1/z583Xbbbcd9bW5AACE2ooVK5STk6PHHntM55xzTo0TDQMAAIQrPq4IBGDBggV65JFH9P333+vAgQNq2bKlRo8erd/97neKimJWDAA4s4wdO1Yvv/yyzj77bM2YMeOUzksJAADgFgy5AAAAAAAA4HqckwsAAAAAAACud8Z9zsrn82n79u1KTEyUx+MJdTkA4HqO42j//v3KzMxURAR/25DoNQBQ1+g1NdFnAKBuBdpnzrgh1/bt2zmRNwAEQW5urpo3bx7qMs4I9BoACA56zSH0GQAIjpP1mTNuyJWYmBjqEgAgLPH++qPD90X//v0D/vKI5ORk023U5kspCgoKTHmv12vK792715S3Hn3QsGFDU16SUlJSTPnt27eb8m3btjXlS0tLTXlJ2rVrlym/Zs0aU75ly5amfEZGhilfm4GE9X7Ky8sz5a3P7fXr15vyI0eONOUl6auvvjLlrc/Vdu3amfIVFRWmvCQVFRWZ8nv27Ak4W11drZycHHrN/+J+AIDgONn76xk35OJwXgAIDt5ff3T4voiKigp4GBUdHW26jdoMuazXCXZN1ueMtR5JiomJMeWt62BdfnV1tSkv2dfb+lGuYD8vrAMlyX4/WWuy5iMjI0352NhYU14K/uvN+lytzXdHWWuy3q8SveYw7gcACI6Tvb8G7QPz06dPV+vWrRUbG6vevXvr888/D9ZNAQDqIfoMACCY6DMA4D5BGXK99tprmjRpkqZMmaKvvvpK3bt319ChQ82H8wMAcCz0GQBAMNFnAMCdgjLk+stf/qLx48frlltuUadOnfT0008rPj5e//znP4/KlpeXq7i4uMYPAAAnYukzEr0GAGBDnwEAd6rzIVdFRYVWrlypwYMH/3gjEREaPHiwli1bdlR+6tSpSk5O9v/wLSQAgBOx9hmJXgMACBx9BgDcq86HXAUFBaqurlZaWlqNy9PS0pSfn39UfvLkySoqKvL/5Obm1nVJAIAwYu0zEr0GABA4+gwAuFfIv13R6/XW6lt9AAAIFL0GABBM9BkAODPU+ZFcqampioyM1M6dO2tcvnPnTqWnp9f1zQEA6hn6DAAgmOgzAOBedT7kiomJUY8ePbRw4UL/ZT6fTwsXLlSfPn3q+uYAAPUMfQYAEEz0GQBwr6B8XHHSpEkaM2aMevbsqV69emnatGkqKSnRLbfcEoybAwDUM/QZAEAw0WcAwJ2CMuS69tprtXv3bj388MPKz8/X2Wefrffff/+okzcCAFAbddVnvF6voqOjA8r+8MMPpmUfPHjQlJek/v37m/Jr16415aOibG0/JSXFlLfWL0nffvutKZ+VlWXKFxQUmPLbt2835SWpW7dupvzevXtNeevHo6qqqkz5lStXmvKSFB8fb8pHRNg+PGC9jyorK035RYsWmfKStHHjRlPe+u16SUlJpvzs2bNNeUkaNWqUKd+xY8eAs+Xl5fr666+tJZ2x2J8BAHcK2onnJ06cqIkTJwZr8QCAeo4+AwAIJvoMALhPnZ+TCwAAAAAAADjdGHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1okJdAAAAoRIVFaWoqMBaYVJSkmnZ3bp1M9fz7bffmvLbt2835Xv27GnK5+XlmfLLli0z5SWpYcOGpvxHH31kyg8dOtSUf+ONN0x5SYqNjTXlHccx5dPT0035GTNmmPIXXnihKS9JFRUVpnzLli1N+ZSUFFPeWk+bNm1Mecn+uFl99tlnpnxqaqr5Nr7++mtTPjk5OeBsZWWltRwAAOocR3IBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1okJdAAAAoRIfH6+YmJiAsj6fz7TskpIScz3t27c35bt3727Kf/vtt6Z8RkaGKV9aWmrKS1JmZqYp37NnT1O+devWpvyVV15pykvSnj17TPmoKNvmV1pamimfmppqyl9xxRWmvCTNnTvXlE9JSTHlP/nkE1Pe+lz94IMPTHlJ6t27tyn/4YcfmvI9evQw5bOzs015SaqurjblHccJOFtRUWEtBwDqjMfjCeryLe+HCC2O5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA60WFugAAAEKloKBA0dHRAWXT0tJMy/b5fOZ6IiMjTfkffvghqMv//vvvTfmtW7ea8pJ05ZVXmvK5ubmm/P79+4Oal6QvvvjClL/zzjtN+U8//dSU79+/vyn/1ltvmfK1sXPnTlP+rLPOMuWLi4tNeet9JEmO45jyHTt2NOXz8vJM+dq83i699FJTfuPGjQFnKysrreUAOEN4PJ4zKn8msm7XWXsG6g5HcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9aJCXQAAAKFy4MABRUUF1gojIyNNy27RooW5nry8PFP+008/NeUHDhxoyjdp0sSUD/S+PFJ8fLwpX1paasrHxsaa8l6v15SXpH79+pny33//vSm/adMmU76srMyU79u3rykvSQsWLDDlPR6PKW99/WzdutWUj4uLM+UlacWKFab8eeedZ8pbX2/W9yRJ+uKLL0z5Sy+9NOBsWVmZ3nnnHWtJAM4A1vdoa7+Pjo425WtzG1ZVVVVBzVdXV5vykuQ4TlDzVhER9mOirL2psrIy4KzjOAGtM0dyAQAAAAAAwPUYcgEAAAAAAMD16nzI9fvf/14ej6fGT4cOHer6ZgAA9RR9BgAQbPQaAHCnoHzQtXPnzvroo49+vJEgf54WAFC/0GcAAMFGrwEA9wnKO3VUVJTS09ODsWgAAOgzAICgo9cAgPsE5Zxc69atU2ZmprKzs3XjjTee8BtvysvLVVxcXOMHAIATsfQZiV4DALBjnwYA3KfOh1y9e/fWjBkz9P777+vvf/+7Nm3apAsvvFD79+8/Zn7q1KlKTk72/9TmK9cBAPWHtc9I9BoAgA37NADgTnU+5Bo+fLhGjRqlbt26aejQoXrvvfdUWFioWbNmHTM/efJkFRUV+X9yc3PruiQAQBix9hmJXgMAsGGfBgDcKehnT0xJSdFZZ52l9evXH/P3Xq9XXq832GUAAMLUyfqMRK8BAJwa9mkAwB2Cck6uIx04cEAbNmxQRkZGsG8KAFAP0WcAAMFGrwEAd6jzIdd9992npUuXavPmzfr3v/+tq666SpGRkbr++uvr+qYAAPUQfQYAEGz0GgBwpzr/uGJeXp6uv/567dmzR02aNFG/fv20fPlyNWnSpK5vCgBQD9Vln2ncuLGio6MDym7atMm07PLycnM9Xbp0MeW7d+9uymdnZ5vy1m8Hq82JlnNycoJ6G23btjXlExMTTXlJ+vvf/27Kd+jQwZS3roNVUVGR+TolJSWmfGxsrCm/cuVKU760tNSULysrM+WlQ+dosrCek6lp06am/Jo1a0x5SbrhhhtM+RdffDHgbFVVlbWcMxr7NHAzj8djykdF2cYC1o/mNm7c2JSXDn1E2CIpKcmUt/a+Xbt2mfIHDx405SX7+6j1cY6JiTHlA91GPpJ1HSzbmo7jBLT8Oh9y/etf/6rrRQIA4EefAQAEG70GANwp6OfkAgAAAAAAAIKNIRcAAAAAAABcjyEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXI8hFwAAAAAAAFwvKtQFAHCXyMhIU97n85nyjuOY8rXh9XpN+fLyclO+bdu2prwkrV+/3nwdnLrVq1crIiKwv/ecc845pmXv3r3bXE9hYaEp37BhQ1O+qKjIlP/iiy9M+bPOOsuUl6SMjAxTPjo62pTPzc015VNSUkx5SerVq5cpP3DgQFN+1apVpvzOnTtN+dLSUlNektLS0kz5PXv2mPLW15v1ubd161ZTXjr0fmFRUFBgyldWVpryPXv2NOUl6emnnzbl27VrF3DWWj+A4Al02+Yw6/Z9QkKCKZ+VlWXKS1L37t1Nees20YEDB0z5devWmfL5+fmmvCSVlZWZ8jExMaZ8VJRt/GPd5pKkHTt2mPLFxcXm2zgZjuQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrRYW6AOBM4vF4gpr3+XymfLNmzUx5SerTp48pP3/+fFO+pKTElD8TlZeXB3X5I0eONF/nT3/6UxAqwcm0b99e0dHRAWXT09NNy67N82zTpk2m/JAhQ0z5tWvXmvKXXHKJKf/hhx+a8pLUoEEDUz47O9uUz8rKMuXnzp1ryktScnKyKf/kk0+a8j/72c9M+dzcXFO+V69eprxkX+fVq1eb8ps3bzblf/jhB1M+Ksq+CTxmzBhT/s9//rMpv2XLFlN+4MCBprwkde7c2ZSPjY0NOFtRUWEtB0CArPscERG2Y1ms74nW3t2pUydTXpLOPvtsU75Ro0amfGRkpCnfsWNHU37Pnj2mfG0kJCSY8tZ90drs91m3BTdu3Bhw1nGcgHIcyQUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA14sKdQGAm/l8vqAu/8ILLzRfp3fv3qZ8ZmamKf+3v/3NlD8TNW3a1JQfOnSoKV9cXGzKI3TS0tIUExMTUDYxMdG07L1795rrOffcc035BQsWmPKtW7c25fPz8035Hj16mPKS1KVLF1P+9ddfN+UdxzHlW7ZsacpL0tatW035yspKUz4vL8+U79u3rym/fft2U16yP5fGjx9vys+aNcuUt77vXnDBBaa8ZH89tG/f3pS3PvcSEhJMeUmKjo425Tt37hxwtqyszFoOgCCJiLAdyxIbG2vKp6WlmfKdOnUy5SUpOzvblPd6vaa8dZ3btGljyhcWFprykv092sq6/VFUVGS+jaVLl5rylu20QLMcyQUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA14sKdQHAmSQyMtKUr6qqMuV79uxpynfs2NGUl6SdO3ea8u3atTPl586da8rv3bvXlI+LizPlJWnLli2mfOPGjU35pKQkUz4vL8+UR+h4vV7FxMQElF2yZIlp2VlZWeZ61qxZY8qnpaWZ8gcOHDDlrTwej/k6H374oSmfnp5uyufn55vy5557rikvSZ06dTLlrb3m3XffNeW3bt1qys+ZM8eUl6TZs2eb8tb36YkTJ5ryGzduNOW//fZbU16SsrOzTfm+ffua8pmZmaa8td9L0pdffhm0fHV1tbUcoF6qTa+0Xicqyrabb92esPY967a0JBUVFZnyqampprz1PoqOjjblGzZsaMpL9vdRr9dryhcWFpry8fHxprykgLerg4kjuQAAAAAAAOB6DLkAAAAAAADgeuYh18cff6zLL79cmZmZ8ng8mjdvXo3fO46jhx9+WBkZGYqLi9PgwYO1bt26uqoXABDm6DMAgGCizwBA+DIPuUpKStS9e3dNnz79mL9//PHH9be//U1PP/20VqxYoQYNGmjo0KEqKys75WIBAOGPPgMACCb6DACEL/OJ54cPH67hw4cf83eO42jatGl68MEHdeWVV0qSXnzxRaWlpWnevHm67rrrTq1aAEDYo88AAIKJPgMA4atOz8m1adMm5efna/Dgwf7LkpOT1bt3by1btuyY1ykvL1dxcXGNHwAAjqU2fUai1wAAAkOfAQB3q9Mh1+Gv6f7pV5CmpaUd9yu8p06dquTkZP9PixYt6rIkAEAYqU2fkeg1AIDA0GcAwN1C/u2KkydPVlFRkf8nNzc31CUBAMIMvQYAEEz0GQA4M9TpkCs9PV2StHPnzhqX79y50/+7n/J6vUpKSqrxAwDAsdSmz0j0GgBAYOgzAOBudTrkysrKUnp6uhYuXOi/rLi4WCtWrFCfPn3q8qYAAPUQfQYAEEz0GQBwN/O3Kx44cEDr16/3/3/Tpk1atWqVGjVqpJYtW+ruu+/W//k//0ft2rVTVlaWHnroIWVmZmrEiBF1WTcAIEzRZwAAwUSfAYDwZR5yffnllxo4cKD//5MmTZIkjRkzRjNmzNCvf/1rlZSU6LbbblNhYaH69eun999/X7GxsXVXNRCgiAjbwYpVVVWmfIMGDUz5UaNGmfLl5eWmvCTzay0xMdGU93g8prz1MbAuX5I6d+5sylvPk7Fv3z5TPirK/NaKI5zOPrNv3z5FR0cHlLW+3leuXGmu55JLLjHly8rKTHnre8ratWtN+dTUVFNekrp06WLKx8XFmfIHDx405Xfs2GHKS4eO/LCorq425TMyMkz50aNHm/JPPPGEKS8dej1avPfee6a89XGzvhbatGljyktS06ZNTXlrr+nfv78pv337dlNekvkjdJb3vaqqKvN7RqiwP4O6ZN12rc22bqDbKoelpKSY8q1atTLlzzrrLFPe+p4u2fdRrNs4Pp/PlHccx5S37ldKUmRkpClv3SayfutrZWWlKS8d+ui2RW1eDydj3hMbMGDACR9gj8ejRx99VI8++ugpFQYAqJ/oMwCAYKLPAED4Cvm3KwIAAAAAAACniiEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXC8q1AWgdjwejynvOI75NiIibDNQ621Y85GRkaa8JFVXV5uvY3H77beb8vn5+aZ8WVmZKS9JrVu3NuVjY2NN+Z07d5ry1sfN5/OZ8pJUUlJiyldUVJjySUlJprzX6zXlJalBgwamvHWdcWz79u1TVFRwWuGgQYPM19m7d68pv379elPe2jsyMzNN+do891NSUkz5VatWmfJdu3Y15ZctW2bKS1JBQYEpn5ycbMqPHz/elF+xYoUp37JlS1Neknbs2GHK33HHHab8f/7zH1M+Ly/PlLc+LyT7+3SLFi1MeWtvqs17V8OGDU15yzZCZWWltRzgtLD2vmAvPzo62nwbiYmJpny7du1M+fPPP9+UT0hIMOWt+5WS/X6qqqoy34bFwYMHTfna7NNYt6Os+9PWmpo0aWLKS1JGRoYpb9lXdBwnoP17juQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOtFhbqAcOXxeEx5x3GCmq8Nn88X1OVHRkaa8tXV1UGq5EfXX3+9KZ+enm7Kf/XVV6Z8dHS0KS9JKSkppvyePXtM+b1795ryqamppnxiYqIpL9mfS1YREba/B8THx5tvo127dqb8qlWrzLeBo8XExAT8OrM+D5YtW2auJysry5Rv0aKFKT9//nxTvkOHDqb8ggULTHlJOuuss0z5YcOGmfKLFy825Rs3bmzKS9KGDRtM+QcffNCUt74vtmzZ0pQvKSkx5SVp3759pvxDDz1kyiclJZnyvXr1MuWXL19uykvSoEGDTHnr47Zu3TpTfvjw4aa8JG3ZssWUr6ysDDhbUVFhLQcws+5j1eY61u1Ka74227rWXjlkyBBT3rr/YFWbdY6NjTXlY2Jigrp8a742+9LW3metyfo4FBUVmfKSlJ2dbcpHRQU+knIcJ6Bew5FcAAAAAAAAcD2GXAAAAAAAAHA9hlwAAAAAAABwPYZcAAAAAAAAcD2GXAAAAAAAAHA9hlwAAAAAAABwPYZcAAAAAAAAcD2GXAAAAAAAAHA9hlwAAAAAAABwPYZcAAAAAAAAcD2GXAAAAAAAAHC9qFAXEK4cxwnq8iMibPNJa16SqqurTXnrOluXXxu33HKLKd++fXtTPjc315RPTU015T0ejykvSXFxcab8tm3bTPnExERT3ufzmfIHDx405SUpNjbWlLfer8F+PUvS0KFDTflVq1YFp5B6Jjc3V5GRkQFlrc/9Xr16mevZvn27KW99zxo2bJgp37NnT1O+srLSlJek/fv3m/KPPfaYKX/rrbea8vn5+aa8JHXq1MmUt75Pf/nll6Z88+bNTfmysjJTXpK8Xq8pn56ebsr369fPlLfep7179zblJfv9al3nefPmmfKvvvqqKS9JnTt3NuWff/75gLNVVVXWchCGarPtahETE2O+TnR0tCkf6HbBYdb3n3POOceUl6Q+ffqY8gkJCaZ8cXGxKd+4cWNT3roPJEkpKSmmvPVxtj5XrfeptX7J3o+t+/ilpaWmvPW5LUlnn3120G7D5/MFtK/IkVwAAAAAAABwPYZcAAAAAAAAcD2GXAAAAAAAAHA9hlwAAAAAAABwPYZcAAAAAAAAcD2GXAAAAAAAAHA9hlwAAAAAAABwPYZcAAAAAAAAcD2GXAAAAAAAAHA9hlwAAAAAAABwPYZcAAAAAAAAcL2oUBcQChERwZ/tOY5jyns8HlPe5/MFNX86ZGZmmvJXX321+Tbi4uJM+XXr1pnyCQkJprzX6zXlGzdubMpLUkVFhSlvfa7Gx8eb8lbV1dXm65SXlwf1NkpKSkz52rze+vbta74OTl3Xrl0VExMTUHbz5s2mZW/dutVcT3p6uim/fPlyU/6bb74x5a2v94MHD5rykpSWlmbKX3zxxaa89fU7bNgwU16SvvjiC1O+srLSlM/LyzPld+7cacp37tzZlJek119/3ZQfPny4Kb9jxw5T3nofWfuxZN+m+Pzzz035/Px8U/6yyy4z5SUpKsq26d+qVauAs5WVlVq5cqW1JJyC2uzTREdHB6GS2rOug/V1KEkNGjQw5a3b37169TLlu3fvbspL0vr16035qqoqU75Zs2amvHUfaO/evaa8ZH+uNmrUyJRPSkoy5a3Po9ooKCgw5a29zLqPkpiYaMpLUvv27U15y+Pg8/kCei5xJBcAAAAAAABcjyEXAAAAAAAAXM885Pr44491+eWXKzMzUx6PR/Pmzavx+7Fjx8rj8dT4qc2h/wCA+ok+AwAIJvoMAIQv85CrpKRE3bt31/Tp04+bGTZsmHbs2OH/efXVV0+pSABA/UGfAQAEE30GAMKX+cTzw4cPP+nJQ71er/nkuQAASPQZAEBw0WcAIHwF5ZxcS5YsUdOmTdW+fXvdcccd2rNnz3Gz5eXlKi4urvEDAMCJWPqMRK8BANjQZwDAnep8yDVs2DC9+OKLWrhwof70pz9p6dKlGj58uKqrq4+Znzp1qpKTk/0/LVq0qOuSAABhxNpnJHoNACBw9BkAcC/zxxVP5rrrrvP/u2vXrurWrZvatGmjJUuWaNCgQUflJ0+erEmTJvn/X1xcTFMAAByXtc9I9BoAQODoMwDgXkH5uOKRsrOzlZqaqvXr1x/z916vV0lJSTV+AAAI1Mn6jESvAQDUHn0GANwj6EOuvLw87dmzRxkZGcG+KQBAPUSfAQAEE30GANzD/HHFAwcO1PgrxqZNm7Rq1So1atRIjRo10iOPPKKRI0cqPT1dGzZs0K9//Wu1bdtWQ4cOrdPCAQDhiT4DAAgm+gwAhC/zkOvLL7/UwIED/f8//NnzMWPG6O9//7tycnL0wgsvqLCwUJmZmRoyZIgee+wxeb1e0+1ERETI4/EElD3RSSCPxefzmfKng+M4QV1+kyZNzNdp1aqVKd+hQwdT3vrXsIqKClNekvmbbVJSUkx566Ho0dHRprz1dSPZn9/Wx9m6DoWFhaZ8ZWWlKS/Z1zkiwnYQa2lpqSkfGRlpykvS/v37TfnOnTsHnK2urtaaNWusJYXM6eozkvTFF1/U6vEKhPW1Itnfs7Zv327KR0XZ2v7GjRtNeWsfkKTWrVub8p06dTLlrb3D+v4gSc2bNzflrTX97Gc/M+UPHDhgymdnZ5vyktSyZUtTvkuXLqb8J598Yspb1+Gbb74x5SX742x9rlqXX5vt2ffee8+UtzxXa9O/Q+V09hmPxxPwPk1MTIxp2bGxseZ6rNu61nW27pc1aNDAlE9NTTXlJalZs2amfFZWlilvrWnXrl2mvGTvG5mZmaa8dV/Uum3csGFDU16S4uLiTHnrc9W6H2fdRrNuc0n29/Xy8nJT3lqT9XGWpMTERFPe8vqprq7W5s2bT5oz3/MDBgw44Yvggw8+sC4SAAA/+gwAIJjoMwAQvoJ+Ti4AAAAAAAAg2BhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPWiQl3A8fh8vqAtOy0tzXydVq1amfINGjQIaj4uLs6Uz8rKMuUlKT4+3pSvrKw05Q8cOGDKR0TYZ7LJycmmvPV+raqqMuWt9+nBgwdNeUkqLy835WNiYkz5HTt2mPLWx8B6H0nSvn37TPmEhARTvmHDhqZ8SUmJKS9J6enppnzjxo0Dzlqfp/XJ6NGjFRsbG1D266+/Ni37ggsuMNezbNkyU97aOxo1amTKn3322ab8qlWrTHnJ/vrdvXu3KV9QUGDKt27d2pSXpB49epjyGzZsMOU/++wzUz4qyrZ5V5vtIsdxTPnVq1eb8tbtwOzsbFPe+jyS7Ns51nyTJk1Mees2iyT169fPlE9KSgo4W15ernfffddaUtjzeDzyeDwBZa3bApmZmeZ6rM8b6zZTSkqKKW99/0lNTTXlJfs6FBYWmvLr16835Wvz2rU+NyIjI01563uu9T5t3ry5KS/Zt7+t+4rbtm0L6vJrs09j3WaPjo425a3rUJuZjLX3WfZFA71/OJILAAAAAAAArseQCwAAAAAAAK7HkAsAAAAAAACux5ALAAAAAAAArseQCwAAAAAAAK7HkAsAAAAAAACux5ALAAAAAAAArseQCwAAAAAAAK7HkAsAAAAAAACux5ALAAAAAAAArseQCwAAAAAAAK4XFeoC6sLgwYNN+czMTPNtVFZWmvJNmzY15SMibPNGn89nylvrl6T9+/eb8gkJCaZ8enq6Ke/xeEx5SfJ6vab8vn37THnr42a9jyIjI015SSopKTHlrY9zUVGRKW99LZwO1sfZ+nqLi4sz5SUpJibGlK+qqgpKtr754IMPFBUVWCvs27evadkNGjQw19O4cWNTvlWrVqZ87969Tfnc3FxTftSoUaa8JH333XemvPU+6tKliym/Y8cOU16Stm3bZsqvXr3alO/Ro4cp37FjR1PeWr9k7wVlZWWm/LvvvmvKt23b1pTPyMgw5SVpz5495utYVFRUmPLW178kFRQUmPLbt28POGutv75ISUkJeHtx4MCBpmWfffbZ5noKCwtNees2kLX3WfPl5eWmvGR/7R48eNCUt/alZs2amfKSfZ8jLS3NlLe+fq3b99Z9stqw7ita+5J1vyzQ7csj1Waf3SI6OtqUt77+pTNjv4MjuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgelGhLuB4Lr74YkVFBVbeuHHjTMtes2aNuZ4dO3aY8sXFxaZ8ZGSkKV9RURHU5dfG/v37TfmYmBhTvrq62pSXpKSkJFPe4/GY8nFxcaa8z+cz5aOjo015SUpPTzfl09LSTPnOnTub8tZ1OB3P1ZKSElM+Pj7elC8rKzPlJXtNu3btCjhrfd7VJ926dZPX6w0om5mZaVq2NS/Z30dbtWplyh84cMCUz8jIMOVro3Xr1qa8tb/m5OSY8qmpqaa8dOh5ZJGdnW3Kr1y50pQP9Dl9mLX3SVJEhO3vpJdeemlQl79lyxZTPtBtzCP97Gc/M+Xz8vJM+fXr15vyixYtMuUl+3N17969AWcrKyut5dQL2dnZAT/f+vbta1q2ddtBsm8nWl+LjuOY8rGxsaZ8bd6jDx48aMpb30MbNGhgylv3HyT7Po31cbbuZ1VVVZnytdm+t25/W59L1sfZ+h5nfQwk+z6+tSbrPoG1Hsn+emjYsGHA2UDXlyO5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6UaEu4HhWrlwpj8cTUPb88883Lbtr167mevr27Wu+jkVVVZUpv3//flN+7969pnxtrlNUVGTKx8TEmPKBPh+O1LhxY1O+ffv2pnx8fLwpn5SUZMo7jmPKS1L37t1N+ZycHFN+8+bNpvzgwYNNea/Xa8pLtbufLKyvz23btplvo7i42JRPSEgIOFtdXW0tp9748ssvFRUVWCu84IILTMvesmWLuZ5mzZqZ8rGxsaZ8QUGBKd+6dWtTfv369aa8JK1evdqUT0tLM+UbNWpkym/atMmUl+z9rF+/fqb8DTfcYMp//fXXpnxkZKQpL0kXX3yxKb9s2TJTvkmTJqb8sGHDTHlrPZLUokULU/6LL74w5fv372/Kz54925SXpA0bNpjylve9srIyvfPOO9aSwl5cXFzAfSbQ3GHR0dHmeqzvidb3B+t2nPU9vTbbidb9pogI23Eg1l5cG3FxcaZ8cnKyKV9RURHUfGJioikv2bdfc3NzTXnr/kNKSoopX1lZacpLh95Hg8lak3X/XpJKSkpMeUtNge6TcSQXAAAAAAAAXI8hFwAAAAAAAFzPNOSaOnWqzjvvPCUmJqpp06YaMWKE1q5dWyNTVlamCRMmqHHjxkpISNDIkSO1c+fOOi0aABCe6DMAgGCj1wBA+DINuZYuXaoJEyZo+fLlWrBggSorKzVkyJAan7u855579Pbbb2v27NlaunSptm/frquvvrrOCwcAhB/6DAAg2Og1ABC+TGc3fP/992v8f8aMGWratKlWrlypiy66SEVFRfrHP/6hV155xX9C0ueff14dO3bU8uXLzSeIBwDUL/QZAECw0WsAIHyd0jm5Dp9t//C3dKxcuVKVlZU1vk2tQ4cOatmy5XG/xaa8vFzFxcU1fgAAkOqmz0j0GgDA8bFPAwDho9ZDLp/Pp7vvvlt9+/ZVly5dJEn5+fmKiYk56us109LSlJ+ff8zlTJ06VcnJyf4f69czAwDCU131GYleAwA4NvZpACC81HrINWHCBH333Xf617/+dUoFTJ48WUVFRf6f3NzcU1oeACA81FWfkeg1AIBjY58GAMKL6Zxch02cOFHvvPOOPv74YzVv3tx/eXp6uioqKlRYWFjjLx87d+5Uenr6MZfl9Xrl9XprUwYAIEzVZZ+R6DUAgKOxTwMA4cd0JJfjOJo4caLmzp2rRYsWKSsrq8bve/TooejoaC1cuNB/2dq1a7V161b16dOnbioGAIQt+gwAINjoNQAQvkxHck2YMEGvvPKK3nzzTSUmJvo/k56cnKy4uDglJydr3LhxmjRpkho1aqSkpCT96le/Up8+ffgWEgDASdFnAADBRq8BgPDlcRzHCTjs8Rzz8ueff15jx46VJJWVlenee+/Vq6++qvLycg0dOlRPPfXUCT9GcqTi4mIlJycHWtJpk5CQYMr37t3blD/rrLNM+QsuuMCUb9q0qSkvSUlJSaZ8gwYNTPnjPZ+Ox/BU9fP5fKb83r17Tfk1a9aY8gsWLDDl58+fb8pLh16DZ5K33nrLlG/ZsqX5NgoKCkz5/fv3BzVfVVVlykuHvpXJ4r777gs46ziODh48qKKiIvPr+nQ7HX1G+rHXXHPNNYqOjg7oOtbHtbCw0JSXDn17l0Xbtm1N+SVLlpjyjRs3NuXvuusuU16y308bN2405c855xxTfvXq1aa8JPXr18+Unzt3rinfsWNHU/61114z5Tds2GDKS1JFRYUp36tXL1P+RN+WeizTp0835ePi4kx5SeZvy/vpSctP5ptvvjHlayMmJsaUP/ytg4EoLS3VHXfcQa/5X4f7TEJCQsDbvG3atAkod1irVq1MeUnmE+JnZGSY8tbHvlmzZqa8dX+jNqz7HNb3k9p8rNW63xQRYTv1tvX9zbptXJtz1G3bts2U3759uymfmZlpyl988cWmfMOGDU15SYqNjTXlIyMjTfnKykpT3trrJftzz7JPU1VVpU8++eSkfcZ0JFcgL/jY2FhNnz7dvLEBAAB9BgAQbPQaAAhftf52RQAAAAAAAOBMwZALAAAAAAAArseQCwAAAAAAAK7HkAsAAAAAAACux5ALAAAAAAAArseQCwAAAAAAAK7HkAsAAAAAAACux5ALAAAAAAAArseQCwAAAAAAAK7HkAsAAAAAAACux5ALAAAAAAAArudxHMcJdRFHKi4uVnJycqjLAICwU1RUpKSkpFCXcUY43GsmTZokr9cb0HWWL19uuo309HRzXRdeeKEpb23hc+bMMeVXr15tylvrl6Rdu3aZ8tXV1aZ827ZtTfndu3eb8pJUVlZmym/bts2UHzBggCm/Y8cOU764uNiUl6T9+/eb8pWVlaZ8ixYtgpr/9ttvTXnJfj9t377dlD///PNN+YKCAlNesr9G58+fH3C2urpaP/zwA73mf9VmnyYiwnb8QWRkpCkvSVFRUaZ8XFycKR8dHW3KW++jlJQUU16SEhMTTXnr/WqtKSYmxpSX7M+N0tJSU37Dhg2mvLVXWuuRpKqqKlPeeh+1bt3alG/WrJkpH+j25ZGsr89gKyoqMl9n3759pvyqVasCzjqOo/Ly8pP2GY7kAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDreRzHcUJdxJGKi4uVnJwc6jIAIOwUFRUpKSkp1GWcEQ73mpYtWyoiIrC/94waNcp0GwsXLjTX5fP5TPmf//znpvxnn31myicmJpryDRs2NOUladOmTab8rl27THnrfRoZGWnKS1KfPn1M+bVr15ryLVu2NOX3799vyl988cWmvCT97W9/M+VjY2NN+aZNm5ry1sf58ssvN+Ulad68eaZ8VVWVKX/gwAFTvlOnTqa8JBUWFprylZWVAWerqqr00Ucf0Wv+F/s0gfF4PEHNSwq4z9c2b+0btdn9rq6uNl/Hwvoeas3X5nEL9nPD+jhbH7farLP1frXWdDpGP6ejppP1GY7kAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrMeQCAAAAAACA6zHkAgAAAAAAgOsx5AIAAAAAAIDrRYW6AAAAQqVjx46Kjo4OKLtgwQLTsidPnmyuZ/r06ab87t27TfmoKFvbz8jIMOU3btxoyktSt27dTPnly5eb8m3atDHl9+3bZ8pL9udGixYtTPl169aZ8l6v15T3+XymvCTFxcWZ8oWFhaZ8bGysKd+oUSNT/n/+539MeUm6/PLLTfkPPvjAfBsW1sdAkiorK0353NzcgLNVVVXWcgA5jhPUvFS79zi383g8pnxt7tdgL/9MWwe4B0dyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1GHIBAAAAAADA9RhyAQAAAAAAwPUYcgEAAAAAAMD1okJdAAAAoVJYWKioqMBaYZ8+fUzLfuedd8z1NG7c2JTPyckx5Vu2bGnKv/fee6Z8ly5dTHlJWr58uSnft29fU37btm2mfG5urikvSd27dzflmzVrZsrPnz/flN+3b58pv337dlNeklJSUkz5K664wpT/7rvvTPn8/HxTPi0tzZSXpL1795ry5557rim/atUqU37z5s2mvCQ1atTIlPd4PEHJAggux3FCXcIpC4d1QGhwJBcAAAAAAABcjyEXAAAAAAAAXM805Jo6darOO+88JSYmqmnTphoxYoTWrl1bIzNgwAB5PJ4aP7fffnudFg0ACE/0GQBAsNFrACB8mYZcS5cu1YQJE7R8+XItWLBAlZWVGjJkiEpKSmrkxo8frx07dvh/Hn/88TotGgAQnugzAIBgo9cAQPgynXj+/fffr/H/GTNmqGnTplq5cqUuuugi/+Xx8fFKT0+vmwoBAPUGfQYAEGz0GgAIX6d0Tq6ioiJJR39Ty8yZM5WamqouXbpo8uTJOnjw4HGXUV5eruLi4ho/AABIddNnJHoNAOD42KcBgPBhOpLrSD6fT3fffbf69u1b4yvDb7jhBrVq1UqZmZnKycnRb37zG61du1Zz5sw55nKmTp2qRx55pLZlAADCVF31GYleAwA4NvZpACC81HrINWHCBH333Xf69NNPa1x+2223+f/dtWtXZWRkaNCgQdqwYYPatGlz1HImT56sSZMm+f9fXFysFi1a1LYsAECYqKs+I9FrAADHxj4NAISXWg25Jk6cqHfeeUcff/yxmjdvfsJs7969JUnr168/ZkPwer3yer21KQMAEKbqss9I9BoAwNHYpwGA8GMacjmOo1/96leaO3eulixZoqysrJNeZ9WqVZKkjIyMWhUIAKg/6DMAgGCj1wBA+DINuSZMmKBXXnlFb775phITE5Wfny9JSk5OVlxcnDZs2KBXXnlFl1xyiRo3bqycnBzdc889uuiii9StW7egrAAAIHzQZwAAwUavAYDwZRpy/f3vf5ckDRgwoMblzz//vMaOHauYmBh99NFHmjZtmkpKStSiRQuNHDlSDz74YJ0VDAAIX/QZAECw0WsAIHx5HMdxQl3EkYqLi5WcnBzqMgAg7BQVFSkpKSnUZZwRDvea+++/P+BzqCxYsMB0G1deeaW5rj/84Q+m/C9/+UtTvrCw0JRfsmSJKV9aWmrKS1KjRo1Meetz2OfzmfJjxowx5SVp0aJFpvzq1atN+auuusqU//e//23KN2vWzJSXpJKSElPe+riVlZWZ8unp6ab8li1bTHnJ/lzKyckx5Xv27GnKR0REmPKStHfvXlPe4/EEnK2qqtLixYvpNf+LfRoACI6T9Rl7dwQAAAAAAADOMAy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HoMuQAAAAAAAOB6DLkAAAAAAADgegy5AAAAAAAA4HpRoS4AAIBQ2b59u2JiYgLKdunSxbTsf//73+Z6LrvsMlP+zTffNOU7dOhgyg8ZMsSU37x5sykvSRERtr+3VVZWmvJjx4415ZcvX27KS1JUlG1zKjExMaj59PR0Uz4uLs6Ul6StW7ea8mlpaaa8x+Mx5SsqKkz5Jk2amPKS9O6775ry3bp1M+ULCwtN+QMHDpjyktS8eXPzdQJlfW0CABAMHMkFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXY8gFAAAAAAAA14sKdQE/5ThOqEsAgLDE++uPDt8XlZWVAV8nIsL2dyHLsmt7HZ/PF9TlV1RUBHX5kv1+raqqMuUPHjxoypeXl5vykn29retQVlZmygf7cZbs62C9DWs+MjLSlLfWL9lfb9bbCHZeqt1r1Lpses0h3A8AEBwne3/1OGfYO3BeXp5atGgR6jIAIOzk5uaqefPmoS7jjECvAYDgoNccQp8BgOA4WZ8544ZcPp9P27dvV2Jiojwej//y4uJitWjRQrm5uUpKSgphhadXfVxv1pl1DlehWmfHcbR//35lZmaaj5oJV/SaH7HOrHO4Yp1P7zrTa2qiz/yIdWadwxXrfGb2mTPu44oREREnnMolJSXVmyfQkerjerPO9QPrfHokJyef1ts709FrjsY61w+sc/0QqnWm1/yIPnM01rl+YJ3rhzO5z/BnFgAAAAAAALgeQy4AAAAAAAC4nmuGXF6vV1OmTJHX6w11KadVfVxv1rl+YJ1xJqqPjxHrXD+wzvVDfVxnt6mPjxHrXD+wzvWDG9b5jDvxPAAAAAAAAGDlmiO5AAAAAAAAgONhyAUAAAAAAADXY8gFAAAAAAAA12PIBQAAAAAAANdjyAUAAAAAAADXc82Qa/r06WrdurViY2PVu3dvff7556EuKWh+//vfy+Px1Pjp0KFDqMuqUx9//LEuv/xyZWZmyuPxaN68eTV+7ziOHn74YWVkZCguLk6DBw/WunXrQlNsHTnZOo8dO/aox33YsGGhKbaOTJ06Veedd54SExPVtGlTjRgxQmvXrq2RKSsr04QJE9S4cWMlJCRo5MiR2rlzZ4gqPnWBrPOAAQOOeqxvv/32EFWMw+gz4dVnJHpNfeg19Bn6jNvQa8Kr19Bnwr/PSPQat/UaVwy5XnvtNU2aNElTpkzRV199pe7du2vo0KHatWtXqEsLms6dO2vHjh3+n08//TTUJdWpkpISde/eXdOnTz/m7x9//HH97W9/09NPP60VK1aoQYMGGjp0qMrKyk5zpXXnZOssScOGDavxuL/66qunscK6t3TpUk2YMEHLly/XggULVFlZqSFDhqikpMSfueeee/T2229r9uzZWrp0qbZv366rr746hFWfmkDWWZLGjx9f47F+/PHHQ1QxJPpMOPYZiV5zPOHUa+gz9Bk3odeEX6+hzxxbOPUZiV7jul7juECvXr2cCRMm+P9fXV3tZGZmOlOnTg1hVcEzZcoUp3v37qEu47SR5MydO9f/f5/P56Snpzt//vOf/ZcVFhY6Xq/XefXVV0NQYd376To7juOMGTPGufLKK0NSz+mya9cuR5KzdOlSx3EOPa7R0dHO7Nmz/ZkffvjBkeQsW7YsVGXWqZ+us+M4Tv/+/Z277rordEXhKPSZ8EevOSTcew195hD6zJmJXhPe6DOHhHufcRx6zWFnaq8544/kqqio0MqVKzV48GD/ZRERERo8eLCWLVsWwsqCa926dcrMzFR2drZuvPFGbd26NdQlnTabNm1Sfn5+jcc8OTlZvXv3DuvHXJKWLFmipk2bqn379rrjjju0Z8+eUJdUp4qKiiRJjRo1kiStXLlSlZWVNR7rDh06qGXLlmHzWP90nQ+bOXOmUlNT1aVLF02ePFkHDx4MRXkQfaY+9hmJXhOuvYY+8yP6zJmFXlP/eg19Jjz7jESvOdKZ2GuiQl3AyRQUFKi6ulppaWk1Lk9LS9OaNWtCVFVw9e7dWzNmzFD79u21Y8cOPfLII7rwwgv13XffKTExMdTlBV1+fr4kHfMxP/y7cDRs2DBdffXVysrK0oYNG/TAAw9o+PDhWrZsmSIjI0Nd3inz+Xy6++671bdvX3Xp0kXSocc6JiZGKSkpNbLh8lgfa50l6YYbblCrVq2UmZmpnJwc/eY3v9HatWs1Z86cEFZbf9Fn6l+fkeg14dhr6DP0mTMZvab+9Rr6TPj1GYle44Zec8YPueqj4cOH+//drVs39e7dW61atdKsWbM0bty4EFaGYLruuuv8/+7atau6deumNm3aaMmSJRo0aFAIK6sbEyZM0HfffRd252I4keOt82233eb/d9euXZWRkaFBgwZpw4YNatOmzekuE/UQfab+CudeQ5/5EX0GZwJ6Tf0Uzn1Gotcc6UztNWf8xxVTU1MVGRl51DcT7Ny5U+np6SGq6vRKSUnRWWedpfXr14e6lNPi8ONanx9zScrOzlZqampYPO4TJ07UO++8o8WLF6t58+b+y9PT01VRUaHCwsIa+XB4rI+3zsfSu3dvSQqLx9qN6DP1r89I9JrDwqXX0GfoM2c6ek396zX0mUPCpc9I9Bq39JozfsgVExOjHj16aOHChf7LfD6fFi5cqD59+oSwstPnwIED2rBhgzIyMkJdymmRlZWl9PT0Go95cXGxVqxYUW8ec0nKy8vTnj17XP24O46jiRMnau7cuVq0aJGysrJq/L5Hjx6Kjo6u8VivXbtWW7dude1jfbJ1PpZVq1ZJkqsfazejz9S/PiPRaw5ze6+hz9Bn3IJeU/96DX3mELf3GYle47peE8qz3gfqX//6l+P1ep0ZM2Y433//vXPbbbc5KSkpTn5+fqhLC4p7773XWbJkibNp0ybns88+cwYPHuykpqY6u3btCnVpdWb//v3O119/7Xz99deOJOcvf/mL8/XXXztbtmxxHMdx/vjHPzopKSnOm2++6eTk5DhXXnmlk5WV5ZSWloa48to70Trv37/fue+++5xly5Y5mzZtcj766CPn3HPPddq1a+eUlZWFuvRau+OOO5zk5GRnyZIlzo4dO/w/Bw8e9Gduv/12p2XLls6iRYucL7/80unTp4/Tp0+fEFZ9ak62zuvXr3ceffRR58svv3Q2bdrkvPnmm052drZz0UUXhbjy+o0+E359xnHoNfWh19Bn6DNuQq8Jv15Dnwn/PuM49Bq39RpXDLkcx3GeeOIJp2XLlk5MTIzTq1cvZ/ny5aEuKWiuvfZaJyMjw4mJiXGaNWvmXHvttc769etDXVadWrx4sSPpqJ8xY8Y4jnPoK3cfeughJy0tzfF6vc6gQYOctWvXhrboU3SidT548KAzZMgQp0mTJk50dLTTqlUrZ/z48a7f6DnW+kpynn/+eX+mtLTU+a//+i+nYcOGTnx8vHPVVVc5O3bsCF3Rp+hk67x161bnoosucho1auR4vV6nbdu2zv333+8UFRWFtnDQZ8KszzgOvaY+9Br6DH3Gbeg14dVr6DPh32cch17jtl7jcRzHqf1xYAAAAAAAAEDonfHn5AIAAAAAAABOhiEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXI8hFwAAAAAAAFyPIRcAAAAAAABcjyEXAAAAAAAAXO//AwNNdXM2DzVWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1500x1500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1행 3열, figsize=(15,15)인 표를 하나 생성하십시오.\n",
    "# 원본 이미지, 오염된 이미지, 복원된 이미지를 불려오고 (28, 28)로 reshape하십시오\n",
    "# 원본 이미지, 오염된 이미지, 복원된 이미지를 각각 출력하십시오.\n",
    "\n",
    "f, a = plt.subplots(1, 3, figsize=(15, 15)) #1행 3열의 표\n",
    "\n",
    "# 시각화를 위해 넘파이 행렬로 바꿔줍니다.\n",
    "original_img = np.reshape(original_x.to(\"cpu\").data.numpy(), (28, 28))\n",
    "noisy_img = np.reshape(noisy_x.to(\"cpu\").data.numpy(), (28, 28))\n",
    "recovered_img = np.reshape(recovered_x.to(\"cpu\").data.numpy(), (28, 28))\n",
    "\n",
    "# 원본 사진\n",
    "a[0].set_title('Original')\n",
    "a[0].imshow(original_img, cmap='gray')\n",
    "\n",
    "# 오염된 원본 사진\n",
    "a[1].set_title('Noisy')\n",
    "a[1].imshow(noisy_img, cmap='gray')\n",
    "\n",
    "# 복원된 사진\n",
    "a[2].set_title('Recovered')\n",
    "a[2].imshow(recovered_img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b1c9d",
   "metadata": {},
   "source": [
    "오토인코더의 개념에 대하여 배우고 Fashion MNIST 데이터셋으로 간단하게 구현해보면서 오토인코더가 어떻게 동작하고 어떤 결과를 도출하는지 확인하였습니다."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
